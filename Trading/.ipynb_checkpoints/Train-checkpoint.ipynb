{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Setting & data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-994c6c097e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmy_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../data/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'parent'"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + '../'\n",
    "my_path = os.path.abspath(os.path.dirname(__file__))\n",
    "path = os.path.join(my_path, \"../data/test.csv\")\n",
    "print(filename)\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading transformers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at activebus/BERT-DK_rest were not used when initializing BertModel: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load_transformer\n",
    "print('Loading transformers...')\n",
    "transformer_tag = \"activebus/BERT-DK_rest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_tag)\n",
    "transformer = AutoModel.from_pretrained(transformer_tag, add_pooling_layer=False)\n",
    "transformer.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Combined_News_DJIA data...\n",
      "Loading upload_DJIA_table data...\n",
      "Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "      <td>17949.369141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "      <td>17929.990234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "      <td>17694.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "      <td>17409.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "      <td>17140.240234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>2015-09-11</td>\n",
       "      <td>1</td>\n",
       "      <td>Child poverty in Scotland is now so severe tha...</td>\n",
       "      <td>Muslim radicals in Germany are trying to recru...</td>\n",
       "      <td>Al Qaeda Leader Al-Zawahiri Declares War on IS...</td>\n",
       "      <td>Cereal banned from Zimbabwe schools after pupi...</td>\n",
       "      <td>Palestine flag to fly at UN headquarters after...</td>\n",
       "      <td>Hundreds of thousands of Catalans gather in Ba...</td>\n",
       "      <td>Citi's Chief Economist Says China Is 'Financia...</td>\n",
       "      <td>Black Mamba female rangers awarded for anti-po...</td>\n",
       "      <td>...</td>\n",
       "      <td>TPP protesters occupy Prime Minister's office</td>\n",
       "      <td>World nuclear capacity set to grow by 45% by 2035</td>\n",
       "      <td>Scientists: Poorer nations outdo wealthier one...</td>\n",
       "      <td>Turkish Teen Gets Suspended Sentence for Insul...</td>\n",
       "      <td>Female cartoonist on indecency charge for shak...</td>\n",
       "      <td>US intelligence chief says Iraq, Syria may not...</td>\n",
       "      <td>50 kg of gold stolen from Egyptian Mint Author...</td>\n",
       "      <td>Russia: World must arm Syrian government again...</td>\n",
       "      <td>Astronomers resort to crowdfunding to save Aus...</td>\n",
       "      <td>8721.440430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>0</td>\n",
       "      <td>Malcom Turnbull becomes Prime Minister of Aust...</td>\n",
       "      <td>El Nino set to be strongest ever. The most pow...</td>\n",
       "      <td>12 Mexican Tourists and Egyptians Killed After...</td>\n",
       "      <td>Police drop VIP Westminster paedophile ring mu...</td>\n",
       "      <td>A Chinese woman suspected of stealing a $300,0...</td>\n",
       "      <td>Iran's President Rouhani sends message for Jew...</td>\n",
       "      <td>Australia- A former teacher from one of Austra...</td>\n",
       "      <td>In a remarkable technical feat, researchers ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>Egypt Begins Digging Moat To Protect Itself fr...</td>\n",
       "      <td>Vivienne Westwood drives tank to David Cameron...</td>\n",
       "      <td>Three critically endangered Javan rhinoceros c...</td>\n",
       "      <td>Obama Administration Accused of Ignoring Genev...</td>\n",
       "      <td>Taliban storms Afghan jail with suicide bomber...</td>\n",
       "      <td>NASA Launching 4K TV Channel</td>\n",
       "      <td>The Egyptian army announced it has killed 64 a...</td>\n",
       "      <td>Oxfam: Increasing inequality plunging millions...</td>\n",
       "      <td>Czech PM insists migrant quotas 'won't work'</td>\n",
       "      <td>8500.330078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>1</td>\n",
       "      <td>Egyptian Billionaire who wants to purchase pri...</td>\n",
       "      <td>The UN Says US Drone Strikes in Yemen Targetin...</td>\n",
       "      <td>Saudis Accused of Not Taking Refugees Despite ...</td>\n",
       "      <td>Denmark has said it will not participate in th...</td>\n",
       "      <td>US troops return to Iraq to battle Islamic State</td>\n",
       "      <td>West 'ignored Russian offer in 2012 to have Sy...</td>\n",
       "      <td>Hungary Declares Emergency As It Blocks Migran...</td>\n",
       "      <td>Whales to gain 'long-sought protections' as na...</td>\n",
       "      <td>...</td>\n",
       "      <td>They are calling it the great Indian gold rush...</td>\n",
       "      <td>Okinawa governor to block construction of new ...</td>\n",
       "      <td>Ex FIFA adviser: Blatter should face a crimina...</td>\n",
       "      <td>City officials have suspended the mayor of Buc...</td>\n",
       "      <td>Canadian banks helping clients bend rules to m...</td>\n",
       "      <td>Poland &amp;amp; Sweden agree to intensify militar...</td>\n",
       "      <td>North Korea 'restarts nuclear operations' | BBC</td>\n",
       "      <td>Teen Arrested for Planning Alleged ISIS-Inspir...</td>\n",
       "      <td>'Syria Is Emptying'</td>\n",
       "      <td>8403.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuna and mackerel populations suffer catastrop...</td>\n",
       "      <td>Australian Government introduces \"No Jab No Pa...</td>\n",
       "      <td>Norway will soon pay Brazil the final instalme...</td>\n",
       "      <td>Air Canada pilot diverts international flight ...</td>\n",
       "      <td>Nepal to stay secular, proposal for a Hindu na...</td>\n",
       "      <td>'If you are worried about refugees, stop suppo...</td>\n",
       "      <td>Exxon's Own Research Confirmed Fossil Fuels' R...</td>\n",
       "      <td>Scared By Russia, Sweden And Poland Make War Pact</td>\n",
       "      <td>...</td>\n",
       "      <td>Iranian Female Soccer Star Faces Husband-Impos...</td>\n",
       "      <td>WWF - Failing fisheries and poor ocean health ...</td>\n",
       "      <td>Jeremy Corbyn has said Labour can win the 2020...</td>\n",
       "      <td>Croatia says it will allow migrants to travel ...</td>\n",
       "      <td>Flying Korea's farmed dogs to safety - \"Our go...</td>\n",
       "      <td>Turkish presidents office says insulting presi...</td>\n",
       "      <td>Saudi suspends Binladen group over Mecca crane...</td>\n",
       "      <td>Anheuser-Busch InBev, the maker of Budweiser a...</td>\n",
       "      <td>China stocks resume sharp slide as economic wo...</td>\n",
       "      <td>8300.019531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>0</td>\n",
       "      <td>Efficiency up, turnover down: Sweden experimen...</td>\n",
       "      <td>7.9-Magnitude Earthquake Strikes off the Coast...</td>\n",
       "      <td>HPV vaccine should be free for boys, says moth...</td>\n",
       "      <td>US priests accused of sex abuse get a second c...</td>\n",
       "      <td>BBC News: A Russian prank caller has said he a...</td>\n",
       "      <td>Nobel director regretted Obama peace prize.</td>\n",
       "      <td>Saudi Arabia: Juvenile prisoner faces 'death b...</td>\n",
       "      <td>University of Sydney Student Smashes NASA Reco...</td>\n",
       "      <td>...</td>\n",
       "      <td>UK Judge gives Asian pedophile harsher sentenc...</td>\n",
       "      <td>Exxon Believed Deep Dive Into Climate Research...</td>\n",
       "      <td>Jewish Man Dies as Rocks Pelt His Car in East ...</td>\n",
       "      <td>World Wide Fund for Nature says nearly half th...</td>\n",
       "      <td>Threatened, starved: Cook reveals life at Saud...</td>\n",
       "      <td>Global study reveals soaring antibiotic resist...</td>\n",
       "      <td>Burkina Faso 'coup': Presidential guard dissol...</td>\n",
       "      <td>Malicious Cisco router backdoor found on 79 mo...</td>\n",
       "      <td>Russian Authorities Close Down American Center...</td>\n",
       "      <td>8473.490234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1790 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Label                                               Top1  \\\n",
       "0     2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1     2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2     2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3     2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4     2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "...          ...    ...                                                ...   \n",
       "1785  2015-09-11      1  Child poverty in Scotland is now so severe tha...   \n",
       "1786  2015-09-14      0  Malcom Turnbull becomes Prime Minister of Aust...   \n",
       "1787  2015-09-15      1  Egyptian Billionaire who wants to purchase pri...   \n",
       "1788  2015-09-16      1  Tuna and mackerel populations suffer catastrop...   \n",
       "1789  2015-09-17      0  Efficiency up, turnover down: Sweden experimen...   \n",
       "\n",
       "                                                   Top2  \\\n",
       "0               b'BREAKING: Musharraf to be impeached.'   \n",
       "1           b'Bush puts foot down on Georgian conflict'   \n",
       "2                    b\"Russia 'ends Georgia operation'\"   \n",
       "3     b\"When the president ordered to attack Tskhinv...   \n",
       "4     b'War in South Osetia - 89 pictures made by a ...   \n",
       "...                                                 ...   \n",
       "1785  Muslim radicals in Germany are trying to recru...   \n",
       "1786  El Nino set to be strongest ever. The most pow...   \n",
       "1787  The UN Says US Drone Strikes in Yemen Targetin...   \n",
       "1788  Australian Government introduces \"No Jab No Pa...   \n",
       "1789  7.9-Magnitude Earthquake Strikes off the Coast...   \n",
       "\n",
       "                                                   Top3  \\\n",
       "0     b'Russia Today: Columns of troops roll into So...   \n",
       "1     b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2     b'\"If we had no sexual harassment we would hav...   \n",
       "3     b' Israel clears troops who killed Reuters cam...   \n",
       "4     b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "...                                                 ...   \n",
       "1785  Al Qaeda Leader Al-Zawahiri Declares War on IS...   \n",
       "1786  12 Mexican Tourists and Egyptians Killed After...   \n",
       "1787  Saudis Accused of Not Taking Refugees Despite ...   \n",
       "1788  Norway will soon pay Brazil the final instalme...   \n",
       "1789  HPV vaccine should be free for boys, says moth...   \n",
       "\n",
       "                                                   Top4  \\\n",
       "0     b'Russian tanks are moving towards the capital...   \n",
       "1     b'Georgian army flees in disarray as Russians ...   \n",
       "2     b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3     b'Britain\\'s policy of being tough on drugs is...   \n",
       "4     b'Russia exaggerated the death toll in South O...   \n",
       "...                                                 ...   \n",
       "1785  Cereal banned from Zimbabwe schools after pupi...   \n",
       "1786  Police drop VIP Westminster paedophile ring mu...   \n",
       "1787  Denmark has said it will not participate in th...   \n",
       "1788  Air Canada pilot diverts international flight ...   \n",
       "1789  US priests accused of sex abuse get a second c...   \n",
       "\n",
       "                                                   Top5  \\\n",
       "0     b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1         b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2     b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3     b'Body of 14 year old found in trunk; Latest (...   \n",
       "4     b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "...                                                 ...   \n",
       "1785  Palestine flag to fly at UN headquarters after...   \n",
       "1786  A Chinese woman suspected of stealing a $300,0...   \n",
       "1787   US troops return to Iraq to battle Islamic State   \n",
       "1788  Nepal to stay secular, proposal for a Hindu na...   \n",
       "1789  BBC News: A Russian prank caller has said he a...   \n",
       "\n",
       "                                                   Top6  \\\n",
       "0     b'150 Russian tanks have entered South Ossetia...   \n",
       "1     b'What were the Mossad with fraudulent New Zea...   \n",
       "2     b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3     b'China has moved 10 *million* quake survivors...   \n",
       "4     b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "...                                                 ...   \n",
       "1785  Hundreds of thousands of Catalans gather in Ba...   \n",
       "1786  Iran's President Rouhani sends message for Jew...   \n",
       "1787  West 'ignored Russian offer in 2012 to have Sy...   \n",
       "1788  'If you are worried about refugees, stop suppo...   \n",
       "1789        Nobel director regretted Obama peace prize.   \n",
       "\n",
       "                                                   Top7  \\\n",
       "0     b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1     b'Russia angered by Israeli military sale to G...   \n",
       "2     b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3     b\"Bush announces Operation Get All Up In Russi...   \n",
       "4     b'Poland and US agree to missle defense deal. ...   \n",
       "...                                                 ...   \n",
       "1785  Citi's Chief Economist Says China Is 'Financia...   \n",
       "1786  Australia- A former teacher from one of Austra...   \n",
       "1787  Hungary Declares Emergency As It Blocks Migran...   \n",
       "1788  Exxon's Own Research Confirmed Fossil Fuels' R...   \n",
       "1789  Saudi Arabia: Juvenile prisoner faces 'death b...   \n",
       "\n",
       "                                                   Top8  ...  \\\n",
       "0     b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1     b'An American citizen living in S.Ossetia blam...  ...   \n",
       "2     b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n",
       "3                b'Russian forces sink Georgian ships '  ...   \n",
       "4     b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n",
       "...                                                 ...  ...   \n",
       "1785  Black Mamba female rangers awarded for anti-po...  ...   \n",
       "1786  In a remarkable technical feat, researchers ha...  ...   \n",
       "1787  Whales to gain 'long-sought protections' as na...  ...   \n",
       "1788  Scared By Russia, Sweden And Poland Make War Pact  ...   \n",
       "1789  University of Sydney Student Smashes NASA Reco...  ...   \n",
       "\n",
       "                                                  Top17  \\\n",
       "0                   b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1     b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2          b'Why Russias response to Georgia was right'   \n",
       "3     b'US humanitarian missions soon in Georgia - i...   \n",
       "4     b\"Georgia confict could set back Russia's US r...   \n",
       "...                                                 ...   \n",
       "1785      TPP protesters occupy Prime Minister's office   \n",
       "1786  Egypt Begins Digging Moat To Protect Itself fr...   \n",
       "1787  They are calling it the great Indian gold rush...   \n",
       "1788  Iranian Female Soccer Star Faces Husband-Impos...   \n",
       "1789  UK Judge gives Asian pedophile harsher sentenc...   \n",
       "\n",
       "                                                  Top18  \\\n",
       "0     b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1     b'Riots are still going on in Montreal (Canada...   \n",
       "2     b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3                b\"Georgia's DDOS came from US sources\"   \n",
       "4     b'War in the Caucasus is as much the product o...   \n",
       "...                                                 ...   \n",
       "1785  World nuclear capacity set to grow by 45% by 2035   \n",
       "1786  Vivienne Westwood drives tank to David Cameron...   \n",
       "1787  Okinawa governor to block construction of new ...   \n",
       "1788  WWF - Failing fisheries and poor ocean health ...   \n",
       "1789  Exxon Believed Deep Dive Into Climate Research...   \n",
       "\n",
       "                                                  Top19  \\\n",
       "0     b'This is a busy day:  The European Union has ...   \n",
       "1       b'China to overtake US as largest manufacturer'   \n",
       "2            b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3     b'Russian convoy heads into Georgia, violating...   \n",
       "4     b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "...                                                 ...   \n",
       "1785  Scientists: Poorer nations outdo wealthier one...   \n",
       "1786  Three critically endangered Javan rhinoceros c...   \n",
       "1787  Ex FIFA adviser: Blatter should face a crimina...   \n",
       "1788  Jeremy Corbyn has said Labour can win the 2020...   \n",
       "1789  Jewish Man Dies as Rocks Pelt His Car in East ...   \n",
       "\n",
       "                                                  Top20  \\\n",
       "0     b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                        b'War in South Ossetia [PICS]'   \n",
       "2     b'Remember that adorable 62-year-old who led y...   \n",
       "3     b'Israeli defence minister: US against strike ...   \n",
       "4     b'Georgian TV reporter shot by Russian sniper ...   \n",
       "...                                                 ...   \n",
       "1785  Turkish Teen Gets Suspended Sentence for Insul...   \n",
       "1786  Obama Administration Accused of Ignoring Genev...   \n",
       "1787  City officials have suspended the mayor of Buc...   \n",
       "1788  Croatia says it will allow migrants to travel ...   \n",
       "1789  World Wide Fund for Nature says nearly half th...   \n",
       "\n",
       "                                                  Top21  \\\n",
       "0     b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1     b'Israeli Physicians Group Condemns State Tort...   \n",
       "2             b'War in Georgia: The Israeli connection'   \n",
       "3                        b'Gorbachev: We Had No Choice'   \n",
       "4     b'Saudi Arabia: Mother moves to block child ma...   \n",
       "...                                                 ...   \n",
       "1785  Female cartoonist on indecency charge for shak...   \n",
       "1786  Taliban storms Afghan jail with suicide bomber...   \n",
       "1787  Canadian banks helping clients bend rules to m...   \n",
       "1788  Flying Korea's farmed dogs to safety - \"Our go...   \n",
       "1789  Threatened, starved: Cook reveals life at Saud...   \n",
       "\n",
       "                                                  Top22  \\\n",
       "0     b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1     b' Russia has just beaten the United States ov...   \n",
       "2     b'All signs point to the US encouraging Georgi...   \n",
       "3     b'Witness: Russian forces head towards Tbilisi...   \n",
       "4      b'Taliban wages war on humanitarian aid workers'   \n",
       "...                                                 ...   \n",
       "1785  US intelligence chief says Iraq, Syria may not...   \n",
       "1786                       NASA Launching 4K TV Channel   \n",
       "1787  Poland &amp; Sweden agree to intensify militar...   \n",
       "1788  Turkish presidents office says insulting presi...   \n",
       "1789  Global study reveals soaring antibiotic resist...   \n",
       "\n",
       "                                                  Top23  \\\n",
       "0     b'Indian shoe manufactory  - And again in a se...   \n",
       "1     b'Perhaps *the* question about the Georgia - R...   \n",
       "2     b'Christopher King argues that the US and NATO...   \n",
       "3     b' Quarter of Russians blame U.S. for conflict...   \n",
       "4     b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "...                                                 ...   \n",
       "1785  50 kg of gold stolen from Egyptian Mint Author...   \n",
       "1786  The Egyptian army announced it has killed 64 a...   \n",
       "1787    North Korea 'restarts nuclear operations' | BBC   \n",
       "1788  Saudi suspends Binladen group over Mecca crane...   \n",
       "1789  Burkina Faso 'coup': Presidential guard dissol...   \n",
       "\n",
       "                                                  Top24  \\\n",
       "0     b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                    b'Russia is so much better at war'   \n",
       "2                           b'America: The New Mexico?'   \n",
       "3     b'Georgian president  says US military will ta...   \n",
       "4     b'Darfur rebels accuse Sudan of mounting major...   \n",
       "...                                                 ...   \n",
       "1785  Russia: World must arm Syrian government again...   \n",
       "1786  Oxfam: Increasing inequality plunging millions...   \n",
       "1787  Teen Arrested for Planning Alleged ISIS-Inspir...   \n",
       "1788  Anheuser-Busch InBev, the maker of Budweiser a...   \n",
       "1789  Malicious Cisco router backdoor found on 79 mo...   \n",
       "\n",
       "                                                  Top25         price  \n",
       "0              b\"No Help for Mexico's Kidnapping Surge\"  17949.369141  \n",
       "1     b\"So this is what it's come to: trading sex fo...  17929.990234  \n",
       "2     b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  17694.679688  \n",
       "3     b'2006: Nobel laureate Aleksander Solzhenitsyn...  17409.720703  \n",
       "4     b'Philippines : Peace Advocate say Muslims nee...  17140.240234  \n",
       "...                                                 ...           ...  \n",
       "1785  Astronomers resort to crowdfunding to save Aus...   8721.440430  \n",
       "1786       Czech PM insists migrant quotas 'won't work'   8500.330078  \n",
       "1787                                'Syria Is Emptying'   8403.799805  \n",
       "1788  China stocks resume sharp slide as economic wo...   8300.019531  \n",
       "1789  Russian Authorities Close Down American Center...   8473.490234  \n",
       "\n",
       "[1790 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(split_name='train'):\n",
    "    print('Loading {} data...'.format(split_name))\n",
    "    df = pd.read_csv(data_dir + f'{split_name}.csv')\n",
    "    return df\n",
    "df = load_data('Combined_News_DJIA')\n",
    "stock_df = load_data('upload_DJIA_table')\n",
    "df['price'] = stock_df.Close\n",
    "\n",
    "train_df = df[:int(len(df) * 0.9)]\n",
    "valid_df = df[int(len(df) * 0.9):]\n",
    "num_train_batches = (len(train_df) + batch_size - 1) // batch_size\n",
    "num_valid_batches = (len(valid_df) + batch_size - 1) // batch_size\n",
    "# news = pd.read_csv(\"../Combined_News_DJIA.csv\")\n",
    "\n",
    "print(\"Loaded\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "Pre_trained_BERT Finished <br>\n",
    "Need Linear & LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size, num_linear=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.pooler = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.layers = nn.ModuleList([nn.Linear(768 + 1, hidden_size)])\n",
    "        self.layers.extend([nn.Linear(hidden_size, hidden_size) for i in range(num_linear)])\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.output = nn.Linear(hidden_size, 1) \n",
    "    def forward(self, text_embeddings, other_inputs):\n",
    "        pooled_output = self.pooler(text_embeddings)  # (batch_size, 768)\n",
    "        h = torch.cat([pooled_output, other_inputs], 1)  # (batch_size, 768 + 1)\n",
    "#         Add LSTM HERE\n",
    "# \n",
    "# \n",
    "        for layer in self.layers:\n",
    "            h = nn.functional.leaky_relu(layer(h))  # (batch_size, hidden_size)\n",
    "            h = self.dropout(h)\n",
    "        o = self.output(h)  # (batch_size, 1)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "hidden_size = 128\n",
    "num_linear = 1\n",
    "\n",
    "records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(outputs):\n",
    "    logits = torch.sigmoid(outputs)\n",
    "    threshold = 0.5\n",
    "    predictions = torch.zeros(len(logits),1).to(device)\n",
    "    for i in range(len(logits)):\n",
    "        if logits[i] < threshold:\n",
    "            predictions[i] = 0\n",
    "        else:\n",
    "            predictions[i] = 1\n",
    "    return predictions\n",
    "\n",
    "def make_input_batch(i_batch, df, batch_size):\n",
    "    rows = df[i_batch* batch_size : min((i_batch+1) * batch_size, len(df))]\n",
    "    text = rows[rows.columns.difference(['price', 'Label', 'Date'])]\n",
    "    text = text.apply(lambda x :' '.join(x.astype(str)),1).tolist()\n",
    "    text_inputs = tokenizer(text, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    text_inputs = {k : v.to(device) for k, v in text_inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = transformer(**text_inputs, return_dict=True).last_hidden_state[:,0,:]\n",
    "    other_inputs = torch.tensor([rows.price.tolist()], dtype=torch.float32).to(device) # (batch_size, 1)\n",
    "    other_inputs = torch.transpose(other_inputs, 0, 1)\n",
    "    train_labels = torch.tensor([rows.Label.tolist()],dtype=torch.float32).to(device)  \n",
    "    train_labels = torch.transpose(train_labels, 0, 1) # (batch_size, 1)\n",
    "    return text_embeddings, other_inputs, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hid-128-numlin-1\n",
      "0\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:47<00:00,  3.85s/it]\n",
      "valid:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.524022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.00s/it]\n",
      "ep  2:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid acc 0.5376884422110553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.86s/it]\n",
      "ep  3:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.87s/it]\n",
      "ep  4:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.87s/it]\n",
      "valid:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.02s/it]\n",
      "ep  5:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid acc 0.5376884422110553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.86s/it]\n",
      "ep  6:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.86s/it]\n",
      "ep  7:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.86s/it]\n",
      "valid:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.02s/it]\n",
      "ep  8:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid acc 0.5376884422110553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.86s/it]\n",
      "ep  9:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.86s/it]\n",
      "ep 10:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [01:48<00:00,  3.87s/it]\n",
      "valid:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss: nan,  train acc: 0.535196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid acc 0.5376884422110553\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/hid-128-numlin-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-21f9f8cd1160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/hid-128-numlin-1'"
     ]
    }
   ],
   "source": [
    "# save path\n",
    "config = f'hid-{hidden_size}-numlin-{num_linear}'\n",
    "print(config)\n",
    "save_path = data_dir + 'results/' + config\n",
    "\n",
    "# model design\n",
    "model = Model(hidden_size=hidden_size, num_linear=num_linear)\n",
    "if os.path.isfile(save_path + '/model.pt'):\n",
    "    model.load_state_dict(torch.load(save_path + '/model.pt'))\n",
    "model.to(device)\n",
    "\n",
    "# Learning Rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "lmbda = lambda epoch: 0.95\n",
    "scheduler = MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "total_acc = 0\n",
    "print(total_acc)\n",
    "losses, acc_train, acc_valid = [], [], []\n",
    "print(\"Start Training\")\n",
    "for epoch in range(num_epochs):\n",
    "    # train\n",
    "    running_loss = 0.0\n",
    "    total_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    # shuffle train data\n",
    "    train_df = train_df.sample(frac=1, random_state=epoch).reset_index(drop=True)\n",
    "\n",
    "    for i_batch in trange(num_train_batches, desc='ep {:2d}'.format(epoch + 1)):\n",
    "        text_embeddings, other_inputs, train_labels = make_input_batch(i_batch, train_df, batch_size)\n",
    "\n",
    "        # train step\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(text_embeddings, other_inputs)\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record\n",
    "        losses.append(loss.cpu().detach().item())\n",
    "        running_loss += losses[-1]\n",
    "        predictions = compute_predictions(outputs)\n",
    "        total_acc += (predictions == train_labels).sum().item()\n",
    "\n",
    "    print(' loss: %.6f,  train acc: %.6f' % (running_loss / len(train_df), total_acc / len(train_df)))\n",
    "#     print(len(train_df))\n",
    "    acc_train.append(total_acc / len(train_df))\n",
    "    scheduler.step()\n",
    "\n",
    "    # validate\n",
    "    if epoch % 3 == 0:\n",
    "        model.eval()\n",
    "        total_acc = 0\n",
    "        ## need to find valid data\n",
    "        with torch.no_grad():\n",
    "            for i_batch in trange(num_valid_batches, desc='valid'):\n",
    "                text_embeddings, other_inputs, valid_labels = make_input_batch(i_batch, valid_df, batch_size)\n",
    "                outputs = model(text_embeddings, other_inputs)\n",
    "                predictions = compute_predictions(outputs)\n",
    "                total_acc += (predictions == valid_labels).sum().item()\n",
    "\n",
    "        print('valid acc', total_acc / len(valid_df))\n",
    "        acc_valid.append(total_acc / len(valid_df))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "torch.save(model.state_dict(), save_path + '/model.pt')\n",
    "\n",
    "record = json.dumps({\n",
    "    'losses' : losses, 'acc_train' : acc_train, 'acc_valid' : acc_valid, \n",
    "    'num_epochs' : num_epochs, 'batch_size' : batch_size, 'lr' : lr, 'hidden_size':hidden_size, 'num_linear':num_linear,\n",
    "    'transformer_tag' : transformer_tag\n",
    "}, sort_keys=True, indent=4)\n",
    "records.append(record)\n",
    "with open(save_path + f'/record-{num_epochs}.json', 'w') as f:\n",
    "    f.write(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_p = data_dir + f'results/records-{num_epochs}.json'\n",
    "\n",
    "with open(records_p, 'r') as f:\n",
    "    records = json.loads(f.read())\n",
    "records = [json.loads(record) for record in records]\n",
    "records = {(r['hidden_size'], r['num_linear']) : r for r in records}\n",
    "\n",
    "fig, axs = plt.subplots(len(hidden_sizes), len(num_linears), sharex=True, sharey=True, figsize=(12,8))\n",
    "axs = axs if len(hidden_sizes) == 1 and len(num_linears) == 1 else axs[ihs, inl]\n",
    "for ihs, hidden_size in enumerate(hidden_sizes):\n",
    "    for inl, num_linear in enumerate(num_linears):\n",
    "        r = records[(hidden_size, num_linear)]\n",
    "        axs.plot([i for i in range(num_epochs)], r['acc_train'])\n",
    "        axs.plot([i for i in range(0, num_epochs, 3)], r['acc_valid'], 'tab:orange')\n",
    "        axs.set_title('hs={}, nl={} ({:.1f})'.format(hidden_size, num_linear, r['acc_valid'][-1]*100))\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     ax.set(xlabel='epochs', ylabel='accuracy')\n",
    "#     # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "#     ax.label_outer()\n",
    "\n",
    "fig.savefig(data_dir + f'results/plt-{num_epochs}.png')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
